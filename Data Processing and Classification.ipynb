{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77b0e840-45e4-408e-bcfb-badc87971953",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the file paths\n",
    "feedback_file_path = \"/mnt/AI-Boost-Project/feedback.csv\"\n",
    "product_usage_file_path = \"/mnt/AI-Boost-Project/product_usage.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d2307e1-6cc6-4fc1-a399-8f88cae11d19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the files as DataFrames\n",
    "feedback_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(feedback_file_path)\n",
    "product_usage_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(product_usage_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c069ebc4-be1d-4856-a2e2-646e73ddb291",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Merge the dataframs on customer_id\n",
    "customer_df = feedback_df.join(product_usage_df, on=\"customer_id\", how=\"left\")\n",
    "\n",
    "# Display the merged DataFrame\n",
    "display(customer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e02904e-ec6c-4134-bfe0-56c77d421eed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "#Initialize Hugging Face client\n",
    "client = InferenceClient(\n",
    "    provider=\"cerebras\",\n",
    "    api_key=os.environ[\"HF_TOKEN\"],\n",
    ")\n",
    "\n",
    "#Collect messages from Spark DataFrame\n",
    "\n",
    "messages_list = [row['message'] for row in customer_df.select(\"message\").collect()]\n",
    "\n",
    "\n",
    "#Create prompt for theme extraction\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are a data analyst. Below is a list of 260 customer support messages.\n",
    "\n",
    "Your task:\n",
    "- Identify exactly 3 to 5 main recurring themes (do not echo messages).\n",
    "- Each theme must be no more than 5 words.\n",
    "- **Return ONLY an array of strings.**\n",
    "- Do NOT include any extra words or explanation\n",
    "\n",
    "\n",
    "Messages:\n",
    "{chr(10).join(messages_list)}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#Call the model\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    max_tokens=300,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "\n",
    "# Extract themes from response\n",
    "if hasattr(completion.choices[0].message, 'content'):\n",
    "    themes = completion.choices[0].message.content\n",
    "else:\n",
    "    themes = str(completion)\n",
    "\n",
    "print(themes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11c04dbd-48f8-4f87-8a5c-36dfb23b90c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Collect messages from Spark DataFrame\n",
    "messages_list = [row['message'] for row in customer_df.select(\"message\").collect()]\n",
    "customer_ids = [row['customer_id'] for row in customer_df.select(\"customer_id\").collect()]\n",
    "\n",
    "\n",
    "#Function to map messages to a theme\n",
    "def classify_message(message, themes):\n",
    "    prompt = f\"\"\"\n",
    "You are an assistant helping classify customer messages.\n",
    "Choose exactly ONE theme from this list of options:\n",
    "\n",
    "{themes}\n",
    "\n",
    "Message:\n",
    "{message}\n",
    "\n",
    "Answer with only the theme text.\n",
    "\"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    max_tokens=300,\n",
    "    temperature=0\n",
    ")\n",
    "    \n",
    "    # Extract the response\n",
    "    try:\n",
    "        return completion.choices[0].message.content.strip()\n",
    "    except Exception:\n",
    "        return \"Unknown\"\n",
    "\n",
    "\n",
    "# Classification\n",
    "results = []\n",
    "for cid, msg in zip(customer_ids, messages_list):\n",
    "    theme = classify_message(msg, themes)\n",
    "    results.append(Row(customer_id=cid, message=msg, theme=theme))\n",
    "\n",
    "\n",
    "# Convert back to Spark DataFrame\n",
    "result_df = spark.createDataFrame(results)\n",
    "\n",
    "# Display results\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80e7b4bc-2f1d-4c21-aa03-504cad2a0288",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Retrieving customer information features\n",
    "customer_info_df = customer_df.select(\n",
    "    \"customer_id\", \"created_at\", \"total_spend\", \"subscription_tier\"\n",
    ")\n",
    "\n",
    "# Merge result_df with customer_info_df on customer_id\n",
    "final_df = result_df.join(\n",
    "    customer_info_df,\n",
    "    on=\"customer_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Write the final DataFrame to a table\n",
    "final_df.write.mode(\"overwrite\").saveAsTable(\"workspace.default.final_customer_themes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03fa8e78-c4bf-4d1a-af76-8662dd572e41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Theme Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d0d7b03-7b2d-486e-93fb-463603871c87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display the final DataFrame\n",
    "display(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0c5d0f1-8956-491b-89f8-e61f04e3376a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Joined View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6ea77ee-090e-4b38-900e-60711677d714",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "\n",
    "#Count number of messages per theme\n",
    "theme_counts = final_df.groupBy(\"theme\").agg(\n",
    "    F.count(\"*\").alias(\"customer_count\"),\n",
    "    F.avg(\"total_spend\").alias(\"avg_total_spend\")\n",
    ")\n",
    "\n",
    "#retrieve a sample message per theme\n",
    "window = Window.partitionBy(\"theme\").orderBy(F.rand())  # random sample\n",
    "sample_messages = result_df.withColumn(\"rn\", F.row_number().over(window)) \\\n",
    "                           .filter(F.col(\"rn\") == 1) \\\n",
    "                           .select(\"theme\", F.col(\"message\").alias(\"sample_message\"))\n",
    "\n",
    "#Join counts and sample messages\n",
    "joined_view = theme_counts.join(sample_messages, on=\"theme\", how=\"left\")\n",
    "\n",
    "#Show the joined view\n",
    "display(joined_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad2453cb-10dc-4ea0-8f9a-d8f6dd1c38bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Theme vs Customer Spend Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8f554a3-8456-46cc-a500-32fb819df595",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert Spark DataFrame to Pandas for plotting\n",
    "pdf = final_df.toPandas()\n",
    "\n",
    "# Count number of messages per theme × subscription tier\n",
    "theme_tier_counts = pdf.groupby(['theme', 'subscription_tier']).size().reset_index(name='count')\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(\n",
    "    x='theme', \n",
    "    y='count', \n",
    "    hue='subscription_tier', \n",
    "    data=theme_tier_counts, \n",
    ")\n",
    "plt.title('Number of Issues by Theme and Subscription Tier')\n",
    "plt.xlabel('Theme')\n",
    "plt.ylabel('Number of Messages')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0, 18)\n",
    "plt.legend(title='Subscription Tier')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4772473934124185,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Data Processing and Classification",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
